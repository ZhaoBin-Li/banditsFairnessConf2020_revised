\section{Related Work}

A wide array of work has focused on using MAB and contextual MAB algorithms for optimization, including applications in advertising and recommendations (e.g.,~\cite{li2010contextual}), crowdsourcing (e.g.,~\cite{jain2014multiarmed}), and designing experiments and clinical trials (e.g.,~\cite{villar2015multi}). Within educational technologies, MAB algorithms have been primarily used in two ways. Some work has used these algorithms to select problems that are of an appropriate difficulty level for a particular student~\cite{clement2015multi,lan2016contextual,segal2018combining}; unlike our work, these applications typically combine learned profiles about students with a second source of knowledge, such as prerequisite structure. 
%. Like our application of choosing which version of a technology to give to each student, the primary goal of these applications is to improve student outcomes, often measured via student mastery of the material or the efficiency with which students master the material. However, unlike our application, these applications typically combine learned profiles about students with a second source of knowledge, such as explicit theories about learning (e.g., choosing problems in the Zone of Proximal Development) or knowledge about problem concepts.%, or the prerequisite structures of particular problems. 
We focus on a second proposed usage of MAB algorithms in education: assigning students to a particular version of a technology. For example, non-contextual MAB algorithms have been used to choose among crowdsourced explanations~\cite{williams2016axis} and to explore an extremely large range of interface designs~\cite{lomas2016interface}. Some of this work has also considered the implications of collecting experimental data via MAB algorithms on measurement and inference~\cite{liu2014trading,rafferty2019statistical}, showing systematic biases that can impair the drawing of conclusions about the conditions. Only a limited amount of work has applied contextual MAB algorithms to personalize which versions of a technology a student experiences (e.g.,~\cite{shaikh2019balancing}, but focused primarily on measurement). We build on this body of work by considering the performance implications of several common scenarios for how student characteristics, versions of an educational technology, and outcomes are related. Additionally, by specifically examining some scenarios in which student characteristics are unevenly distributed, we raise issues about personalization for minority groups of students. 
%We limit our focus to how well the MAB algorithm chooses the best version for each student, rather than measurement.

There is a great deal of theory-based literature on both standard and contextual MAB algorithms related to quantifying performance, especially in terms of asymptotically bounding growth in cumulative regret (the amount that the expected reward from choosing an optimal action outpaces reward from the actually chosen actions). The optimal worst-case bound on regret growth is logarithmic~\cite{auer2002using}.
%, although in particular settings constant regret can be achieved with high probability~\cite{abbasi2011improved}.
Furthermore, the inclusion of contextual variables increases cumulative regret at least linearly; for Thompson sampling, which we use in our simulations, the regret bounds grow quadratically in the number of contextual variables~\cite{agrawal2013thompson}.  %This theoretical work emphasizes asymptotic regret growth, and finite horizon applications typically focus on a fixed horizon (e.g.,~\cite{lattimore2016regret}). 
We use simulations to consider non-asymptotic settings and focus on areas less explored theoretically, like impacts on individual groups of students and variability in performance.
%, including cases that have been less explored theoretically like the performance consequences for particular subsets of the population when contextual variable values are non-uniformly distributed.


In this paper, we are particularly concerned with how outcomes differ among different groups of students. One of the promises of educational technologies is to boost all students' outcomes to the level that can be achieved by individualized tutoring~\cite{corbett2001cognitive}, and online adaptive algorithms may make it easier to develop such systems. Yet, the broader machine learning community  has recently highlighted how automated systems can learn or exacerbate existing inequalities (see, e.g.,~\cite{hajian2016algorithmic} for an overview). 
% Yet there has only been some limited consideration of fairness for bandit algorithms, albeit in a different setting than ours~\cite{joseph2016fairness}.
Within educational data mining, there have been mixed results when the fairness of different models has been explored, and this variation has often been correlated with the diversity of the training data: \cite{hutt2019evaluating} demonstrated that a model trained on a large and diverse dataset performed similarly well for predicting on-time graduation for students in different demographic groups, while  \cite{gardner2019evaluating} found disparities across genders in predicting course dropout, often associated with gender imbalances in the training data. This raises the issue of how to best use educational data mining in ways that promote equity across students.
Within the MAB literature specifically, there has been limited discussion of fairness (e.g.,~\cite{joseph2016fairness}), although~\cite{pmlr-v75-raghavan18a} show that a particular technical definition of data diversity can lead to fairer outcomes. Like in our work,~\cite{pmlr-v75-raghavan18a} shows cases where the presence or absence of a majority group can help or harm minority group outcomes. Our work considers scenarios specific to education, demonstrating that the particular scenario in~\cite{pmlr-v75-raghavan18a} can be generalized considerably, and more precisely characterizes the circumstances in which including personal characteristics increases equity versus where doing so may lead to systematically poorer experiences for students in a minority group.

%Online adaptation that learns from data from prior students has the potential to make it possible to realize these gains more quickly, even in smaller systems with less prior data available or less developed theories about what will be effective for whom. Enabling this online adaptation and providing the algorithm with the ability to personalize based on student characteristics means that the algorithm can systematically treat students differently based on their characteristics



% Things to include:
% \begin{itemize}
%     \item Paragraph about uses of contextual and non-contextual bandits in education. Differentiate between focusing on inference versus only reward.
%     \item Paragraph about known theoretical results concerning contextual versus non-contextual performance, highlight that we're focused on student-relevant horizons and the fairness angle.
%     \item Paragraph about increasing interest in fairness both in machine learning and specifically EDM.
% \end{itemize}
